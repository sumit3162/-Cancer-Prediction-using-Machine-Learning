# ğŸ¥ Cancer Prediction using Machine Learning

## ğŸ“Œ Project Overview

This project is designed to predict whether a tumor is malignant or benign based on a dataset containing various medical features. Using machine learning algorithms like Support Vector Machine (SVM), Random Forest, and XGBoost, the model learns patterns from historical data and makes accurate predictions. The project also includes data preprocessing, exploratory data analysis (EDA), hyperparameter tuning, and model evaluation to ensure high performance and reliability.
This project aims to predict cancer diagnoses based on medical data using various machine learning techniques. The dataset used contains features extracted from breast cancer cell images, and the goal is to classify them as malignant or benign.

## âœ¨ Features of the Project

- ğŸ“Š Data preprocessing (handling missing values, encoding categorical data, feature selection)
- ğŸ” Exploratory Data Analysis (EDA) with heatmaps, box plots, and distribution plots
- ğŸ¤– Model training using multiple algorithms:
  - ğŸ”¹ Support Vector Machine (SVM)
  - ğŸŒ³ Random Forest Classifier
  - ğŸš€ XGBoost Classifier
- âš™ï¸ Hyperparameter tuning using GridSearchCV
- ğŸ“ˆ Model evaluation using accuracy, confusion matrix, and classification report
- âš–ï¸ Data balancing using SMOTE (Synthetic Minority Over-sampling Technique)
- ğŸ’¾ Saving and loading models using Pickle

## ğŸ“¦ Requirements

The following libraries are required to run the project:

```python
numpy
pandas
matplotlib
seaborn
scikit-learn
xgboost
pickle
imblearn
```

## ğŸ“¥ Installation

Use the following command to install the required dependencies:

```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost imbalanced-learn
```

## ğŸ“‚ Dataset

The dataset is stored as `data.csv` and contains:

- ğŸ†” **ID**: Unique identifier
- ğŸ”¬ **Diagnosis**: Malignant (1) or Benign (0)
- ğŸ“Š **Feature Columns**: Various numerical measurements related to tumor characteristics

## ğŸš€ Usage

### 1ï¸âƒ£ Load Dataset

```python
import pandas as pd
data = pd.read_csv('data.csv')
```

### 2ï¸âƒ£ Data Preprocessing

- ğŸ”„ Convert categorical variables to numerical using label encoding
- âŒ Check for null values and handle them if needed
- ğŸ“‰ Perform feature selection based on importance ranking

### 3ï¸âƒ£ Model Training

```python
from sklearn.model_selection import train_test_split
x = data.drop(['diagnosis', 'id'], axis=1)
y = data['diagnosis']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)
```

#### ğŸŒ³ Train a Random Forest Model

```python
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=500, random_state=10)
clf.fit(x_train, y_train)
accuracy = clf.score(x_test, y_test)
print(f'Accuracy: {accuracy}')
```

### 4ï¸âƒ£ Hyperparameter Tuning

```python
from sklearn.model_selection import GridSearchCV
param_grid = {'n_estimators': [100, 500, 1000]}
grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, scoring='accuracy')
grid.fit(x_train, y_train)
print(grid.best_params_)
```

### 5ï¸âƒ£ Save and Load Model

```python
import pickle
pickle.dump(clf, open('random_forest_model.pkl', 'wb'))
loaded_model = pickle.load(open('random_forest_model.pkl', 'rb'))
```

## ğŸ“Š Results

- ğŸ“ˆ Model evaluation metrics include accuracy, confusion matrix, and classification report.
- ğŸ† The best performing model is selected based on the highest accuracy score.

## ğŸ¯ Conclusion

This project successfully implements machine learning models to predict cancer diagnoses. The use of different classifiers and feature selection techniques enhances prediction accuracy. Future improvements can involve deep learning models and more advanced data preprocessing techniques.

## ğŸ‘¨â€ğŸ’» Author

Developed by **Sumit** ğŸš€

